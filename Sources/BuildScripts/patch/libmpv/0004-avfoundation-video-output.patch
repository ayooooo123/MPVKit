From b58aef8eca8a059404be0bf28ce756c355126a45 Mon Sep 17 00:00:00 2001
From: Alex Kim <alexkim@Alexs-MacBook-Pro.local>
Date: Sat, 23 Aug 2025 20:11:28 +1000
Subject: [PATCH] AVfoundation video output

---
 meson.build                 |   8 +
 meson.options               |   1 +
 video/out/vo.c              |   4 +
 video/out/vo_avfoundation.m | 954 ++++++++++++++++++++++++++++++++++++
 4 files changed, 967 insertions(+)
 create mode 100644 video/out/vo_avfoundation.m

diff --git a/meson.build b/meson.build
index 7572769e0e..d74fae0319 100644
--- a/meson.build
+++ b/meson.build
@@ -813,6 +813,14 @@ if features['avfoundation']
     sources += files('audio/out/ao_avfoundation.m')
 endif
 
+vo_avfoundation = dependency('appleframeworks', modules: ['AVFoundation', 'CoreMedia', 'CoreVideo'],
+                             required: get_option('vo-avfoundation'))
+features += {'vo-avfoundation': vo_avfoundation.found()}
+if features['vo-avfoundation']
+    dependencies += vo_avfoundation
+    sources += files('video/out/vo_avfoundation.m')
+endif
+
 coreaudio = dependency('appleframeworks', modules: ['CoreFoundation', 'CoreAudio',
                        'AudioUnit', 'AudioToolbox'], required: get_option('coreaudio'))
 features += {'coreaudio': coreaudio.found()}
diff --git a/meson.options b/meson.options
index dae0a333ef..b8d3ae30ba 100644
--- a/meson.options
+++ b/meson.options
@@ -60,6 +60,7 @@ option('d3d11', type: 'feature', value: 'auto', description: 'Direct3D 11 video
 option('direct3d', type: 'feature', value: 'auto', description: 'Direct3D support')
 option('dmabuf-wayland', type: 'feature', value: 'auto', description: 'dmabuf-wayland video output')
 option('drm', type: 'feature', value: 'auto', description: 'Direct Rendering Manager (DRM)')
+option('vo-avfoundation', type: 'feature', value: 'auto', description: 'AVFoundation video output')
 option('egl', type: 'feature', value: 'auto', description: 'EGL 1.4')
 option('egl-android', type: 'feature', value: 'auto', description: 'Android EGL support')
 option('egl-angle', type: 'feature', value: 'auto', description: 'OpenGL ANGLE headers')
diff --git a/video/out/vo.c b/video/out/vo.c
index 7b5df4b886..3b8bbd0b39 100644
--- a/video/out/vo.c
+++ b/video/out/vo.c
@@ -46,6 +46,7 @@
 #include "osdep/io.h"
 #include "osdep/threads.h"
 
+extern const struct vo_driver video_out_avfoundation;
 extern const struct vo_driver video_out_mediacodec_embed;
 extern const struct vo_driver video_out_x11;
 extern const struct vo_driver video_out_vdpau;
@@ -69,6 +70,9 @@ extern const struct vo_driver video_out_kitty;
 
 static const struct vo_driver *const video_out_drivers[] =
 {
+#if HAVE_VO_AVFOUNDATION
+    &video_out_avfoundation,
+#endif
 #if HAVE_ANDROID
     &video_out_mediacodec_embed,
 #endif
diff --git a/video/out/vo_avfoundation.m b/video/out/vo_avfoundation.m
new file mode 100644
index 0000000000..fe99e4ab1d
--- /dev/null
+++ b/video/out/vo_avfoundation.m
@@ -0,0 +1,954 @@
+/*
+ * This file is part of mpv.
+ *
+ * mpv is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * mpv is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with mpv.  If not, see <http://www.gnu.org/licenses/>.
+ */
+
+#include <libavutil/hwcontext.h>
+#include <libavutil/hwcontext_videotoolbox.h>
+
+#include "common/common.h"
+#include "options/m_option.h"
+#include "osdep/timer.h"
+#include "vo.h"
+#include "video/mp_image.h"
+#include "video/hwdec.h"
+#include "sub/osd.h"
+
+#import <CoreMedia/CoreMedia.h>
+#import <AVFoundation/AVFoundation.h>
+#import <CoreGraphics/CoreGraphics.h>
+#import <CoreImage/CoreImage.h>
+#import <QuartzCore/QuartzCore.h>
+#import <Metal/Metal.h>
+#import <TargetConditionals.h>
+
+#if TARGET_OS_IPHONE
+#import <UIKit/UIKit.h>
+#else
+#import <AppKit/AppKit.h>
+#endif
+
+struct priv {
+    struct mp_hwdec_ctx hwctx;
+
+    struct mp_image *next_image;
+    double next_pts;
+    __strong AVSampleBufferDisplayLayer *displayLayer;
+    
+    // OSD/Subtitle support (CALayer mode)
+    __strong CALayer *osdLayer;
+    int64_t osd_change_id;
+    int osd_w, osd_h;
+    
+    // Compositing mode support
+    bool composite_osd;
+    __strong id<MTLDevice> mtlDevice;
+    __strong CIContext *ciContext;
+    CVPixelBufferPoolRef outputPool;
+    int output_pool_w, output_pool_h;
+    CGImageRef cachedSubtitleImage;
+    bool has_subtitle;
+    
+    // Software frame upload support
+    CVPixelBufferPoolRef swUploadPool;
+    int sw_pool_w, sw_pool_h;
+    OSType sw_pool_format;
+    
+    // Frame counter for periodic maintenance
+    int frame_count;
+    
+    // Track if OSD callback was invoked this frame
+    bool osd_callback_invoked;
+};
+
+// Helper to sync OSD layer frame with display layer bounds
+static void sync_osd_layer_frame(struct priv *p)
+{
+    if (p->composite_osd || !p->osdLayer || !p->displayLayer)
+        return;
+    dispatch_async(dispatch_get_main_queue(), ^{
+        p->osdLayer.frame = p->displayLayer.bounds;
+    });
+}
+
+static AVBufferRef *create_videotoolbox_device_ref(struct vo *vo)
+{
+    AVBufferRef *device_ref = av_hwdevice_ctx_alloc(AV_HWDEVICE_TYPE_VIDEOTOOLBOX);
+    if (!device_ref) {
+        MP_ERR(vo, "Failed to allocate VideoToolbox device\n");
+        return NULL;
+    }
+
+    if (av_hwdevice_ctx_init(device_ref) < 0) {
+        MP_ERR(vo, "Failed to init VideoToolbox device\n");
+        av_buffer_unref(&device_ref);
+        return NULL;
+    }
+
+    return device_ref;
+}
+
+// Generic pixel buffer pool creation helper
+static bool create_pixel_buffer_pool(struct vo *vo, CVPixelBufferPoolRef *poolRef,
+                                     int *cached_w, int *cached_h, OSType *cached_fmt,
+                                     int w, int h, OSType format, const char *name)
+{
+    // Don't recreate if dimensions and format match
+    if (*poolRef && *cached_w == w && *cached_h == h && 
+        (!cached_fmt || *cached_fmt == format))
+        return true;
+    
+    // Release old pool
+    if (*poolRef) {
+        CVPixelBufferPoolFlush(*poolRef, kCVPixelBufferPoolFlushExcessBuffers);
+        CVPixelBufferPoolRelease(*poolRef);
+        *poolRef = NULL;
+    }
+    
+    NSDictionary *poolAttrs = @{
+        (id)kCVPixelBufferPoolMinimumBufferCountKey: @3,
+        (id)kCVPixelBufferPoolMaximumBufferAgeKey: @1.0
+    };
+    
+    NSDictionary *bufferAttrs = @{
+        (id)kCVPixelBufferPixelFormatTypeKey: @(format),
+        (id)kCVPixelBufferWidthKey: @(w),
+        (id)kCVPixelBufferHeightKey: @(h),
+        (id)kCVPixelBufferMetalCompatibilityKey: @YES,
+        (id)kCVPixelBufferIOSurfacePropertiesKey: @{}
+    };
+    
+    CVReturn status = CVPixelBufferPoolCreate(kCFAllocatorDefault,
+        (__bridge CFDictionaryRef)poolAttrs,
+        (__bridge CFDictionaryRef)bufferAttrs, poolRef);
+    
+    if (status != kCVReturnSuccess) {
+        MP_ERR(vo, "Failed to create %s pool: %d\n", name, status);
+        return false;
+    }
+    
+    *cached_w = w;
+    *cached_h = h;
+    if (cached_fmt)
+        *cached_fmt = format;
+    
+    MP_VERBOSE(vo, "Created %s pool: %dx%d format=%d\n", name, w, h, (int)format);
+    return true;
+}
+
+// Create output pool matching the source format to preserve quality
+// Strategy: Use BGRA for 8-bit SDR (matches subtitle format, avoids half-float precision loss)
+//           Use RGBA half-float for 10-bit HDR (necessary for HDR precision)
+static bool create_output_pool(struct vo *vo, int w, int h, OSType format)
+{
+    struct priv *p = vo->priv;
+    
+    OSType outputFormat;
+    
+    // For 10-bit HDR content (P010), use RGBA half-float to preserve HDR precision
+    if (format == kCVPixelFormatType_420YpCbCr10BiPlanarVideoRange ||
+        format == kCVPixelFormatType_420YpCbCr10BiPlanarFullRange) {
+        outputFormat = kCVPixelFormatType_64RGBAHalf;
+    }
+    // For 8-bit SDR content, use BGRA (matches subtitle format, avoids half-float precision issues)
+    // This minimizes format conversions and preserves quality better than RGBA half-float
+    else if (format == kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange ||
+             format == kCVPixelFormatType_420YpCbCr8BiPlanarFullRange ||
+             format == kCVPixelFormatType_420YpCbCr8Planar) {
+        outputFormat = kCVPixelFormatType_32BGRA;
+    }
+    // Default to RGBA half-float for unknown formats (HDR-safe fallback)
+    else {
+        outputFormat = kCVPixelFormatType_64RGBAHalf;
+    }
+    
+    return create_pixel_buffer_pool(vo, &p->outputPool, &p->output_pool_w, 
+        &p->output_pool_h, NULL, w, h, outputFormat, "composite output");
+}
+
+// Copy HDR metadata from source to destination pixel buffer
+static void copy_hdr_metadata(CVPixelBufferRef src, CVPixelBufferRef dst)
+{
+    const CFStringRef keys[] = {
+        kCVImageBufferTransferFunctionKey,      // PQ for HDR10/DolbyVision, HLG for HLG
+        kCVImageBufferColorPrimariesKey,        // BT.2020 for HDR
+        kCVImageBufferYCbCrMatrixKey,
+        kCVImageBufferMasteringDisplayColorVolumeKey,  // HDR10 static metadata
+        kCVImageBufferContentLightLevelInfoKey,        // MaxCLL, MaxFALL
+    };
+    
+    for (size_t i = 0; i < MP_ARRAY_SIZE(keys); i++) {
+        CFTypeRef value = CVBufferGetAttachment(src, keys[i], NULL);
+        if (value) {
+            CVBufferSetAttachment(dst, keys[i], value, kCVAttachmentMode_ShouldPropagate);
+        }
+    }
+}
+
+// Map mpv image format to CVPixelBuffer format
+static OSType get_cv_pixel_format(int imgfmt)
+{
+    switch (imgfmt) {
+        case IMGFMT_NV12:
+            return kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange;
+        case IMGFMT_420P:
+            return kCVPixelFormatType_420YpCbCr8Planar;
+        case IMGFMT_P010:
+            return kCVPixelFormatType_420YpCbCr10BiPlanarVideoRange;
+        default:
+            return 0;
+    }
+}
+
+// Create software upload pool
+static bool create_sw_upload_pool(struct vo *vo, int w, int h, OSType format)
+{
+    struct priv *p = vo->priv;
+    return create_pixel_buffer_pool(vo, &p->swUploadPool, &p->sw_pool_w,
+        &p->sw_pool_h, &p->sw_pool_format, w, h, format, "software upload");
+}
+
+// Upload a software-decoded frame to CVPixelBuffer
+static CVPixelBufferRef upload_software_frame(struct vo *vo, struct mp_image *mpi)
+{
+    struct priv *p = vo->priv;
+    
+    OSType cvFormat = get_cv_pixel_format(mpi->imgfmt);
+    if (!cvFormat) {
+        MP_ERR(vo, "Unsupported software format: %d\n", mpi->imgfmt);
+        return NULL;
+    }
+    
+    int w = mpi->w;
+    int h = mpi->h;
+    
+    if (!create_sw_upload_pool(vo, w, h, cvFormat))
+        return NULL;
+    
+    CVPixelBufferRef pixbuf = NULL;
+    CVReturn status = CVPixelBufferPoolCreatePixelBuffer(
+        kCFAllocatorDefault, p->swUploadPool, &pixbuf);
+    
+    if (status != kCVReturnSuccess || !pixbuf) {
+        MP_ERR(vo, "Failed to get upload buffer: %d\n", status);
+        return NULL;
+    }
+    
+    CVPixelBufferLockBaseAddress(pixbuf, 0);
+    
+    size_t planeCount = CVPixelBufferGetPlaneCount(pixbuf);
+    
+    if (planeCount == 0) {
+        // Non-planar format
+        void *dst = CVPixelBufferGetBaseAddress(pixbuf);
+        size_t dstStride = CVPixelBufferGetBytesPerRow(pixbuf);
+        size_t srcStride = mpi->stride[0];
+        
+        // Fast path: single memcpy if strides match
+        if (dstStride == srcStride) {
+            memcpy(dst, mpi->planes[0], dstStride * h);
+        } else {
+            size_t copyBytes = MPMIN(dstStride, srcStride);
+            for (int y = 0; y < h; y++) {
+                memcpy((uint8_t *)dst + y * dstStride,
+                       mpi->planes[0] + y * srcStride,
+                       copyBytes);
+            }
+        }
+    } else {
+        // Planar format (NV12, YUV420P, P010)
+        for (size_t plane = 0; plane < planeCount && plane < MP_MAX_PLANES; plane++) {
+            void *dst = CVPixelBufferGetBaseAddressOfPlane(pixbuf, plane);
+            size_t dstStride = CVPixelBufferGetBytesPerRowOfPlane(pixbuf, plane);
+            size_t dstHeight = CVPixelBufferGetHeightOfPlane(pixbuf, plane);
+            
+            uint8_t *src = mpi->planes[plane];
+            size_t srcStride = mpi->stride[plane];
+            
+            if (!src)
+                continue;
+            
+            // Fast path: single memcpy if strides match
+            if (dstStride == srcStride) {
+                memcpy(dst, src, dstStride * dstHeight);
+            } else {
+                size_t copyBytes = MPMIN(dstStride, srcStride);
+                for (size_t y = 0; y < dstHeight; y++) {
+                    memcpy((uint8_t *)dst + y * dstStride,
+                           src + y * srcStride,
+                           copyBytes);
+                }
+            }
+        }
+    }
+    
+    CVPixelBufferUnlockBaseAddress(pixbuf, 0);
+    
+    return pixbuf;
+}
+
+// Render subtitle bitmap to CGImage (used by both modes)
+static CGImageRef render_subtitle_image(struct vo *vo, struct sub_bitmaps *imgs)
+{
+    struct priv *p = vo->priv;
+    
+    if (!imgs || imgs->num_parts == 0)
+        return NULL;
+    
+    int w = p->osd_w;
+    int h = p->osd_h;
+    
+    if (w <= 0 || h <= 0)
+        return NULL;
+    
+    CGColorSpaceRef colorSpace = CGColorSpaceCreateDeviceRGB();
+    if (!colorSpace)
+        return NULL;
+    
+    CGContextRef context = CGBitmapContextCreate(
+        NULL, w, h, 8, w * 4, colorSpace,
+        kCGImageAlphaPremultipliedLast | kCGBitmapByteOrder32Big
+    );
+    CGColorSpaceRelease(colorSpace);
+    
+    if (!context)
+        return NULL;
+    
+    CGContextClearRect(context, CGRectMake(0, 0, w, h));
+    
+    // Create colorspace once for all BGRA parts (libass doesn't need it)
+    CGColorSpaceRef partColorSpace = (imgs->format == SUBBITMAP_BGRA) 
+        ? CGColorSpaceCreateDeviceRGB() : NULL;
+    
+    for (int i = 0; i < imgs->num_parts; i++) {
+        struct sub_bitmap *sb = &imgs->parts[i];
+        
+        if (!sb->bitmap || sb->w <= 0 || sb->h <= 0)
+            continue;
+        
+        CGDataProviderRef provider = CGDataProviderCreateWithData(
+            NULL, sb->bitmap, sb->stride * sb->h, NULL);
+        
+        if (!provider)
+            continue;
+        
+        if (imgs->format == SUBBITMAP_BGRA) {
+            CGImageRef partImage = CGImageCreate(
+                sb->w, sb->h, 8, 32, sb->stride, partColorSpace,
+                kCGImageAlphaPremultipliedFirst | kCGBitmapByteOrder32Little,
+                provider, NULL, false, kCGRenderingIntentDefault);
+            
+            if (partImage) {
+                CGRect destRect = CGRectMake(sb->x, h - sb->y - sb->dh, sb->dw, sb->dh);
+                CGContextDrawImage(context, destRect, partImage);
+                CGImageRelease(partImage);
+            }
+        } else if (imgs->format == SUBBITMAP_LIBASS) {
+            // Invert decode array: libass uses 255=opaque, but CGImageMask uses 0=paint
+            CGFloat decode[] = {1, 0};
+            CGImageRef mask = CGImageMaskCreate(
+                sb->w, sb->h, 8, 8, sb->stride, provider, decode, false);
+            
+            if (mask) {
+                CGContextSaveGState(context);
+                CGRect destRect = CGRectMake(sb->x, h - sb->y - sb->dh, sb->dw, sb->dh);
+                CGContextClipToMask(context, destRect, mask);
+                
+                uint32_t c = sb->libass.color;
+                float r = ((c >> 24) & 0xFF) / 255.0f;
+                float g = ((c >> 16) & 0xFF) / 255.0f;
+                float b = ((c >> 8) & 0xFF) / 255.0f;
+                float a = 1.0f - ((c >> 0) & 0xFF) / 255.0f;
+                
+                CGContextSetRGBFillColor(context, r, g, b, a);
+                CGContextFillRect(context, destRect);
+                CGContextRestoreGState(context);
+                CGImageRelease(mask);
+            }
+        }
+        
+        CGDataProviderRelease(provider);
+    }
+    
+    if (partColorSpace)
+        CGColorSpaceRelease(partColorSpace);
+    
+    CGImageRef result = CGBitmapContextCreateImage(context);
+    CGContextRelease(context);
+    
+    return result;
+}
+
+// Callback for osd_draw - renders subtitle bitmaps
+static void draw_osd_cb(void *ctx, struct sub_bitmaps *imgs)
+{
+    struct vo *vo = ctx;
+    struct priv *p = vo->priv;
+    
+    // Mark that callback was invoked this frame
+    p->osd_callback_invoked = true;
+    
+    if (!imgs || imgs->num_parts == 0) {
+        // Clear subtitles when there are none
+        if (p->has_subtitle) {
+            p->has_subtitle = false;
+            if (p->composite_osd) {
+                if (p->cachedSubtitleImage) {
+                    CGImageRelease(p->cachedSubtitleImage);
+                    p->cachedSubtitleImage = NULL;
+                }
+            } else {
+                dispatch_async(dispatch_get_main_queue(), ^{
+                    [CATransaction begin];
+                    [CATransaction setDisableActions:YES];
+                    p->osdLayer.contents = nil;
+                    [CATransaction commit];
+                });
+            }
+        }
+        return;
+    }
+    
+    // Skip redraw if content hasn't changed
+    if (imgs->change_id != 0 && imgs->change_id == p->osd_change_id)
+        return;
+    
+    p->osd_change_id = imgs->change_id;
+    p->has_subtitle = true;
+    
+    CGImageRef subtitleImage = render_subtitle_image(vo, imgs);
+    if (!subtitleImage)
+        return;
+    
+    if (p->composite_osd) {
+        // Compositing mode: cache the image for use in draw_frame
+        if (p->cachedSubtitleImage)
+            CGImageRelease(p->cachedSubtitleImage);
+        p->cachedSubtitleImage = subtitleImage;
+    } else {
+        // CALayer mode: update layer on main thread
+        dispatch_async(dispatch_get_main_queue(), ^{
+            [CATransaction begin];
+            [CATransaction setDisableActions:YES];
+            p->osdLayer.contents = (__bridge id)subtitleImage;
+            CGImageRelease(subtitleImage);
+            [CATransaction commit];
+        });
+    }
+}
+
+// Render OSD/subtitles
+static void render_osd(struct vo *vo, double pts)
+{
+    struct priv *p = vo->priv;
+    
+    if (!vo->osd)
+        return;
+    
+    // In composite mode, we don't need the osdLayer
+    if (!p->composite_osd && !p->osdLayer)
+        return;
+    
+    int w = vo->params ? vo->params->w : 0;
+    int h = vo->params ? vo->params->h : 0;
+    
+    if (w <= 0 || h <= 0)
+        return;
+    
+    p->osd_w = w;
+    p->osd_h = h;
+    
+    struct mp_osd_res osd_res = {
+        .w = w,
+        .h = h,
+        .display_par = 1.0,
+    };
+    
+    static const bool formats[SUBBITMAP_COUNT] = {
+        [SUBBITMAP_BGRA] = true,
+        [SUBBITMAP_LIBASS] = true,
+    };
+    
+    // Reset flag before calling osd_draw
+    p->osd_callback_invoked = false;
+    
+    osd_draw(vo->osd, osd_res, pts, 0, formats, draw_osd_cb, vo);
+    
+    // If callback wasn't invoked, there are no subtitles for this PTS
+    // Clear any cached subtitle state
+    if (!p->osd_callback_invoked && p->has_subtitle) {
+        p->has_subtitle = false;
+        if (p->composite_osd) {
+            if (p->cachedSubtitleImage) {
+                CGImageRelease(p->cachedSubtitleImage);
+                p->cachedSubtitleImage = NULL;
+            }
+        } else if (p->osdLayer) {
+            dispatch_async(dispatch_get_main_queue(), ^{
+                [CATransaction begin];
+                [CATransaction setDisableActions:YES];
+                p->osdLayer.contents = nil;
+                [CATransaction commit];
+            });
+        }
+    }
+}
+
+// Composite subtitle onto video frame using Core Image (GPU) - HDR compatible
+static CVPixelBufferRef composite_frame(struct vo *vo, CVPixelBufferRef videoBuffer)
+{
+    struct priv *p = vo->priv;
+    
+    if (!p->cachedSubtitleImage || !p->has_subtitle)
+        return NULL;
+    
+    size_t w = CVPixelBufferGetWidth(videoBuffer);
+    size_t h = CVPixelBufferGetHeight(videoBuffer);
+    
+    // Detect original pixel format to preserve quality
+    OSType sourceFormat = CVPixelBufferGetPixelFormatType(videoBuffer);
+    
+    // Ensure output pool matches dimensions and format
+    if (!create_output_pool(vo, (int)w, (int)h, sourceFormat))
+        return NULL;
+    
+    // Get output buffer from pool
+    CVPixelBufferRef outputBuffer = NULL;
+    CVReturn status = CVPixelBufferPoolCreatePixelBuffer(
+        kCFAllocatorDefault, p->outputPool, &outputBuffer);
+    
+    if (status != kCVReturnSuccess || !outputBuffer) {
+        MP_ERR(vo, "Failed to get output buffer from pool: %d\n", status);
+        return NULL;
+    }
+    
+    // Copy HDR metadata from input to output buffer BEFORE rendering
+    copy_hdr_metadata(videoBuffer, outputBuffer);
+    
+    // Use autoreleasepool to ensure CIImage objects are released promptly
+    @autoreleasepool {
+        // Create CIImages - preserve color space from source for HDR
+        CGColorSpaceRef srcColorSpace = CVImageBufferGetColorSpace(videoBuffer);
+        CGColorSpaceRef fallbackColorSpace = NULL;
+        if (!srcColorSpace) {
+            fallbackColorSpace = CGColorSpaceCreateWithName(kCGColorSpaceSRGB);
+            srcColorSpace = fallbackColorSpace;
+        }
+        
+        CIImage *videoImage;
+        if (srcColorSpace) {
+            NSDictionary *videoOptions = @{
+                kCIImageColorSpace: (__bridge id)srcColorSpace
+            };
+            videoImage = [CIImage imageWithCVPixelBuffer:videoBuffer options:videoOptions];
+        } else {
+            videoImage = [CIImage imageWithCVPixelBuffer:videoBuffer];
+        }
+        
+        if (fallbackColorSpace)
+            CGColorSpaceRelease(fallbackColorSpace);
+        CIImage *subtitleImage = [CIImage imageWithCGImage:p->cachedSubtitleImage];
+        
+        if (!videoImage || !subtitleImage) {
+            CVPixelBufferRelease(outputBuffer);
+            return NULL;
+        }
+        
+        // Scale subtitle to match video dimensions if needed
+        CGSize videoSize = videoImage.extent.size;
+        CGSize subSize = subtitleImage.extent.size;
+        
+        if (subSize.width != videoSize.width || subSize.height != videoSize.height) {
+            CGFloat scaleX = videoSize.width / subSize.width;
+            CGFloat scaleY = videoSize.height / subSize.height;
+            subtitleImage = [subtitleImage imageByApplyingTransform:
+                CGAffineTransformMakeScale(scaleX, scaleY)];
+        }
+        
+        // Composite subtitle over video
+        CIImage *composited = [subtitleImage imageByCompositingOverImage:videoImage];
+        
+        // Render to output buffer, preserving color space
+        CGColorSpaceRef outputColorSpace = CVImageBufferGetColorSpace(videoBuffer);
+        if (outputColorSpace) {
+            [p->ciContext render:composited 
+                 toCVPixelBuffer:outputBuffer 
+                          bounds:composited.extent
+                      colorSpace:outputColorSpace];
+        } else {
+            [p->ciContext render:composited toCVPixelBuffer:outputBuffer];
+        }
+    }
+    
+    return outputBuffer;
+}
+
+static int preinit(struct vo *vo)
+{
+    struct priv *p = vo->priv;
+
+    if (!vo->opts->WinID) {
+        MP_ERR(vo, "No AVSampleBufferDisplayLayer provided via --wid\n");
+        return -1;
+    }
+    
+    p->displayLayer = (__bridge AVSampleBufferDisplayLayer *)(intptr_t)(vo->opts->WinID);
+    
+    MP_VERBOSE(vo, "displayLayer: %p, composite_osd: %s\n", 
+               p->displayLayer, p->composite_osd ? "yes" : "no");
+
+    // Setup Metal and Core Image for compositing mode (HDR-compatible)
+    if (p->composite_osd) {
+        p->mtlDevice = MTLCreateSystemDefaultDevice();
+        if (!p->mtlDevice) {
+            MP_ERR(vo, "Failed to create Metal device\n");
+            return -1;
+        }
+        
+        // Use extended linear Display P3 color space for HDR compositing
+        // This color space can represent values > 1.0 needed for HDR
+        CGColorSpaceRef workingColorSpace = CGColorSpaceCreateWithName(
+            kCGColorSpaceExtendedLinearDisplayP3);
+        if (!workingColorSpace) {
+            workingColorSpace = CGColorSpaceCreateWithName(kCGColorSpaceExtendedSRGB);
+        }
+        if (!workingColorSpace) {
+            workingColorSpace = CGColorSpaceCreateWithName(kCGColorSpaceSRGB);
+        }
+        
+        NSDictionary *ciOptions = workingColorSpace ? @{
+            kCIContextWorkingColorSpace: (__bridge id)workingColorSpace,
+            kCIContextHighQualityDownsample: @NO,
+            kCIContextUseSoftwareRenderer: @NO
+        } : @{
+            kCIContextHighQualityDownsample: @NO,
+            kCIContextUseSoftwareRenderer: @NO
+        };
+        
+        p->ciContext = [CIContext contextWithMTLDevice:p->mtlDevice options:ciOptions];
+        
+        if (workingColorSpace)
+            CGColorSpaceRelease(workingColorSpace);
+        
+        if (!p->ciContext) {
+            MP_ERR(vo, "Failed to create CIContext\n");
+            return -1;
+        }
+        
+        MP_VERBOSE(vo, "HDR-compatible compositing mode enabled with Metal\n");
+    }
+
+    // Create OSD layer only if not in composite mode
+    if (!p->composite_osd) {
+        dispatch_sync(dispatch_get_main_queue(), ^{
+            p->osdLayer = [CALayer layer];
+            CGRect bounds = p->displayLayer.bounds;
+            p->osdLayer.frame = bounds;
+            p->osdLayer.anchorPoint = CGPointMake(0.5, 0.5);
+            p->osdLayer.position = CGPointMake(CGRectGetMidX(bounds), CGRectGetMidY(bounds));
+            
+#if TARGET_OS_IPHONE
+            p->osdLayer.contentsScale = [UIScreen mainScreen].scale;
+#else
+            p->osdLayer.contentsScale = [NSScreen mainScreen].backingScaleFactor;
+#endif
+            
+            p->osdLayer.backgroundColor = NULL;
+            p->osdLayer.opaque = NO;
+            p->osdLayer.contentsGravity = kCAGravityResizeAspect;
+            
+            [p->displayLayer addSublayer:p->osdLayer];
+        });
+    }
+
+    vo->hwdec_devs = hwdec_devices_create();
+    p->hwctx = (struct mp_hwdec_ctx){
+        .driver_name = "avfoundation",
+        .av_device_ref = create_videotoolbox_device_ref(vo),
+        .hw_imgfmt = IMGFMT_VIDEOTOOLBOX,
+    };
+    hwdec_devices_add(vo->hwdec_devs, &p->hwctx);
+
+    return 0;
+}
+
+static void flip_page(struct vo *vo)
+{
+    struct priv *p = vo->priv;
+    
+    // In CALayer mode, render OSD here (video was enqueued in draw_frame)
+    if (!p->composite_osd) {
+        render_osd(vo, p->next_pts);
+    }
+    
+    // Flush excess buffers every ~60 frames to prevent memory growth
+    // without causing buffer churn on every frame
+    if (++p->frame_count >= 60) {
+        p->frame_count = 0;
+        if (p->outputPool)
+            CVPixelBufferPoolFlush(p->outputPool, kCVPixelBufferPoolFlushExcessBuffers);
+        if (p->swUploadPool)
+            CVPixelBufferPoolFlush(p->swUploadPool, kCVPixelBufferPoolFlushExcessBuffers);
+    }
+    
+    mp_image_unrefp(&p->next_image);
+}
+
+static bool draw_frame(struct vo *vo, struct vo_frame *frame)
+{
+    @autoreleasepool {
+        struct priv *p = vo->priv;
+
+        mp_image_t *mpi = NULL;
+        if (!frame->redraw && !frame->repeat)
+            mpi = mp_image_new_ref(frame->current);
+
+        talloc_free(p->next_image);
+        
+        if (!mpi) {
+            p->next_image = NULL;
+            return true;
+        }
+        
+        double pts = mpi->pts;
+        if (pts == MP_NOPTS_VALUE && frame->current)
+            pts = frame->current->pts;
+        if (pts == MP_NOPTS_VALUE)
+            pts = frame->pts;
+        
+        p->next_pts = pts;
+        
+        CVPixelBufferRef pixbuf = NULL;
+        bool pixbufNeedsRelease = false;
+        
+        // Handle different input formats
+        if (mpi->imgfmt == IMGFMT_VIDEOTOOLBOX) {
+            // Hardware decoded: zero-copy passthrough
+            pixbuf = (CVPixelBufferRef)mpi->planes[3];
+        } else {
+            // Software decoded: upload to CVPixelBuffer
+            pixbuf = upload_software_frame(vo, mpi);
+            if (!pixbuf) {
+                MP_ERR(vo, "Failed to upload software frame\n");
+                mp_image_unrefp(&mpi);
+                return false;
+            }
+            pixbufNeedsRelease = true;
+        }
+        
+        CVPixelBufferRef finalBuffer = pixbuf;
+        bool needsRelease = false;
+        
+        // In composite mode, render OSD and composite onto frame
+        if (p->composite_osd) {
+            render_osd(vo, pts);
+            
+            CVPixelBufferRef composited = composite_frame(vo, pixbuf);
+            if (composited) {
+                finalBuffer = composited;
+                needsRelease = true;
+            }
+        }
+        
+        // Create and enqueue sample buffer
+        CMTimebaseRef timebase = [p->displayLayer controlTimebase];
+        CMTime presentationTime = timebase ? CMTimebaseGetTime(timebase) : kCMTimeInvalid;
+        
+        CMSampleTimingInfo info = {
+            .presentationTimeStamp = presentationTime,
+            .duration = kCMTimeInvalid,
+            .decodeTimeStamp = kCMTimeInvalid
+        };
+
+        CMSampleBufferRef buf = NULL;
+        CMFormatDescriptionRef format = NULL;
+        OSStatus err = CMVideoFormatDescriptionCreateForImageBuffer(NULL, finalBuffer, &format);
+        if (err != noErr || !format) {
+            MP_ERR(vo, "Failed to create format description: %d\n", (int)err);
+            if (needsRelease)
+                CVPixelBufferRelease(finalBuffer);
+            if (pixbufNeedsRelease)
+                CVPixelBufferRelease(pixbuf);
+            mp_image_unrefp(&mpi);
+            return false;
+        }
+        
+        err = CMSampleBufferCreateReadyWithImageBuffer(NULL, finalBuffer, format, &info, &buf);
+        CFRelease(format);
+        
+        if (err != noErr || !buf) {
+            MP_ERR(vo, "Failed to create sample buffer: %d\n", (int)err);
+            if (needsRelease)
+                CVPixelBufferRelease(finalBuffer);
+            if (pixbufNeedsRelease)
+                CVPixelBufferRelease(pixbuf);
+            mp_image_unrefp(&mpi);
+            return false;
+        }
+
+        if (!timebase) {
+            CFArrayRef attachments = CMSampleBufferGetSampleAttachmentsArray(buf, YES);
+            CFDictionarySetValue(
+                (CFMutableDictionaryRef)CFArrayGetValueAtIndex(attachments, 0),
+                kCMSampleAttachmentKey_DisplayImmediately,
+                kCFBooleanTrue
+            );
+        }
+
+        [p->displayLayer enqueueSampleBuffer:buf];
+        CFRelease(buf);
+        
+        // Release composited output buffer (always owned by us)
+        if (needsRelease)
+            CVPixelBufferRelease(finalBuffer);
+        
+        // Release uploaded software frame buffer (owned by us, not by mpi)
+        if (pixbufNeedsRelease)
+            CVPixelBufferRelease(pixbuf);
+        
+        p->next_image = mpi;
+
+        return true;
+    }
+}
+
+static int query_format(struct vo *vo, int format)
+{
+    switch (format) {
+        case IMGFMT_VIDEOTOOLBOX:  // Hardware decoded (zero-copy)
+        case IMGFMT_NV12:          // Software decoded (common)
+        case IMGFMT_420P:          // YUV420P (very common)
+        case IMGFMT_P010:          // 10-bit (HDR software decode)
+            return 1;
+        default:
+            return 0;
+    }
+}
+
+// Helper to clear all subtitle state (called on video change/stop)
+static void clear_subtitle_state(struct vo *vo)
+{
+    struct priv *p = vo->priv;
+    
+    if (p->cachedSubtitleImage) {
+        CGImageRelease(p->cachedSubtitleImage);
+        p->cachedSubtitleImage = NULL;
+    }
+    p->has_subtitle = false;
+    p->osd_change_id = 0;
+    
+    if (!p->composite_osd && p->osdLayer) {
+        dispatch_async(dispatch_get_main_queue(), ^{
+            [CATransaction begin];
+            [CATransaction setDisableActions:YES];
+            p->osdLayer.contents = nil;
+            [CATransaction commit];
+        });
+    }
+}
+
+static int reconfig(struct vo *vo, struct mp_image_params *params)
+{
+    struct priv *p = vo->priv;
+    
+    MP_VERBOSE(vo, "reconfig: %dx%d\n", params->w, params->h);
+    
+    // Clear subtitles when video configuration changes
+    clear_subtitle_state(vo);
+    sync_osd_layer_frame(p);
+    
+    return 0;
+}
+
+static void uninit(struct vo *vo)
+{
+    struct priv *p = vo->priv;
+    
+    mp_image_unrefp(&p->next_image);
+    [p->displayLayer flushAndRemoveImage];
+    
+    if (p->cachedSubtitleImage) {
+        CGImageRelease(p->cachedSubtitleImage);
+        p->cachedSubtitleImage = NULL;
+    }
+    
+    if (p->outputPool) {
+        CVPixelBufferPoolRelease(p->outputPool);
+        p->outputPool = NULL;
+    }
+    
+    if (p->swUploadPool) {
+        CVPixelBufferPoolRelease(p->swUploadPool);
+        p->swUploadPool = NULL;
+    }
+    
+    if (!p->composite_osd) {
+        dispatch_sync(dispatch_get_main_queue(), ^{
+            [p->osdLayer removeFromSuperlayer];
+            p->osdLayer = nil;
+        });
+    }
+    
+    p->ciContext = nil;
+    p->mtlDevice = nil;
+
+    hwdec_devices_remove(vo->hwdec_devs, &p->hwctx);
+    av_buffer_unref(&p->hwctx.av_device_ref);
+}
+
+static int control(struct vo *vo, uint32_t request, void *data)
+{
+    struct priv *p = vo->priv;
+    
+    switch (request) {
+    case VOCTRL_SET_PANSCAN:
+        sync_osd_layer_frame(p);
+        return VO_TRUE;
+    case VOCTRL_RESET:
+        // Called when playback stops or video changes
+        clear_subtitle_state(vo);
+        [p->displayLayer flushAndRemoveImage];
+        return VO_TRUE;
+    case VOCTRL_REDRAW:
+        p->osd_change_id = 0;
+        return VO_TRUE;
+    case VOCTRL_UPDATE_WINDOW_TITLE:
+        return VO_TRUE;
+    }
+    return VO_NOTIMPL;
+}
+
+
+#define OPT_BASE_STRUCT struct priv
+static const struct m_option options[] = {
+    {"composite-osd", OPT_BOOL(composite_osd)},
+    {0},
+};
+
+const struct vo_driver video_out_avfoundation = {
+    .description = "AVFoundation AVSampleBufferDisplayLayer (macOS/iOS)",
+    .name = "avfoundation",
+    .caps = VO_CAP_NORETAIN,
+    .preinit = preinit,
+    .query_format = query_format,
+    .control = control,
+    .draw_frame = draw_frame,
+    .flip_page = flip_page,
+    .reconfig = reconfig,
+    .uninit = uninit,
+    .priv_size = sizeof(struct priv),
+    .options = options,
+    .options_prefix = "avfoundation",
+};
-- 
2.50.1 (Apple Git-155)
